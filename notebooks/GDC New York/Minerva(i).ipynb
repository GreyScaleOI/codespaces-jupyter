{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tweepy in /usr/local/python/3.10.13/lib/python3.10/site-packages (4.14.0)\n",
      "Requirement already satisfied: oauthlib<4,>=3.2.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tweepy) (3.2.2)\n",
      "Requirement already satisfied: requests<3,>=2.27.0 in /home/codespace/.local/lib/python3.10/site-packages (from tweepy) (2.31.0)\n",
      "Requirement already satisfied: requests-oauthlib<2,>=1.2.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tweepy) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.10/site-packages (from requests<3,>=2.27.0->tweepy) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.10/site-packages (from requests<3,>=2.27.0->tweepy) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from requests<3,>=2.27.0->tweepy) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.10/site-packages (from requests<3,>=2.27.0->tweepy) (2024.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "Forbidden",
     "evalue": "403 Forbidden\n453 - You currently have access to a subset of Twitter API v2 endpoints and limited v1.1 endpoints (e.g. media post, oauth) only. If you need access to this endpoint, you may need a different access level. You can learn more here: https://developer.twitter.com/en/portal/product",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mForbidden\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 56\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     55\u001b[0m     username \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnter the Twitter username: \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 56\u001b[0m     \u001b[43manalyze_user_sentiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43musername\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[7], line 16\u001b[0m, in \u001b[0;36manalyze_user_sentiment\u001b[0;34m(username, count)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21manalyze_user_sentiment\u001b[39m(username, count\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m):\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;66;03m# Retrieve tweets from user timeline\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m     tweets \u001b[38;5;241m=\u001b[39m \u001b[43mapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muser_timeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscreen_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musername\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcount\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcount\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtweet_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mextended\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;66;03m# Initialize sentiment scores\u001b[39;00m\n\u001b[1;32m     19\u001b[0m     positive \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/tweepy/api.py:33\u001b[0m, in \u001b[0;36mpagination.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(method)\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 33\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/tweepy/api.py:46\u001b[0m, in \u001b[0;36mpayload.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     44\u001b[0m kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpayload_list\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m payload_list\n\u001b[1;32m     45\u001b[0m kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpayload_type\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m payload_type\n\u001b[0;32m---> 46\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/tweepy/api.py:414\u001b[0m, in \u001b[0;36mAPI.user_timeline\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;129m@pagination\u001b[39m(mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    374\u001b[0m \u001b[38;5;129m@payload\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mlist\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    375\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21muser_timeline\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    376\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"user_timeline(*, user_id, screen_name, since_id, count, max_id, \\\u001b[39;00m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;124;03m                     trim_user, exclude_replies, include_rts)\u001b[39;00m\n\u001b[1;32m    378\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[38;5;124;03m    https://developer.twitter.com/en/docs/twitter-api/v1/tweets/timelines/api-reference/get-statuses-user_timeline\u001b[39;00m\n\u001b[1;32m    413\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 414\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mGET\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstatuses/user_timeline\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendpoint_parameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43muser_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mscreen_name\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msince_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcount\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmax_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrim_user\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mexclude_replies\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minclude_rts\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m    418\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    419\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/tweepy/api.py:271\u001b[0m, in \u001b[0;36mAPI.request\u001b[0;34m(self, method, endpoint, endpoint_parameters, params, headers, json_payload, parser, payload_list, payload_type, post_data, files, require_auth, return_cursors, upload_api, use_cache, **kwargs)\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Unauthorized(resp)\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m403\u001b[39m:\n\u001b[0;32m--> 271\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Forbidden(resp)\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m404\u001b[39m:\n\u001b[1;32m    273\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NotFound(resp)\n",
      "\u001b[0;31mForbidden\u001b[0m: 403 Forbidden\n453 - You currently have access to a subset of Twitter API v2 endpoints and limited v1.1 endpoints (e.g. media post, oauth) only. If you need access to this endpoint, you may need a different access level. You can learn more here: https://developer.twitter.com/en/portal/product"
     ]
    }
   ],
   "source": [
    "import tweepy\n",
    "from textblob import TextBlob\n",
    "\n",
    "# Twitter API credentials\n",
    "consumer_key = ''\n",
    "consumer_secret = ''\n",
    "access_token = ''\n",
    "access_token_secret = ''\n",
    "\n",
    "# Authenticate to Twitter\n",
    "auth = tweepy.OAuth1UserHandler(consumer_key, consumer_secret, access_token, access_token_secret)\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "def analyze_user_sentiment(username, count=100):\n",
    "    # Retrieve tweets from user timeline\n",
    "    tweets = api.user_timeline(screen_name=username, count=count, tweet_mode='extended')\n",
    "    \n",
    "    # Initialize sentiment scores\n",
    "    positive = 0\n",
    "    negative = 0\n",
    "    neutral = 0\n",
    "    \n",
    "    # Analyze sentiment of each tweet\n",
    "    for tweet in tweets:\n",
    "        # Preprocess text (you can implement your own preprocessing steps here)\n",
    "        text = tweet.full_text\n",
    "        \n",
    "        # Perform sentiment analysis\n",
    "        analysis = TextBlob(text)\n",
    "        \n",
    "        # Aggregate sentiment scores\n",
    "        if analysis.sentiment.polarity > 0:\n",
    "            positive += 1\n",
    "        elif analysis.sentiment.polarity < 0:\n",
    "            negative += 1\n",
    "        else:\n",
    "            neutral += 1\n",
    "    \n",
    "    # Determine overall sentiment\n",
    "    total_tweets = positive + negative + neutral\n",
    "    if total_tweets > 0:\n",
    "        positive_percentage = (positive / total_tweets) * 100\n",
    "        negative_percentage = (negative / total_tweets) * 100\n",
    "        neutral_percentage = (neutral / total_tweets) * 100\n",
    "        \n",
    "        print(f\"Overall sentiment for user @{username}:\")\n",
    "        print(f\"Positive: {positive_percentage:.2f}%\")\n",
    "        print(f\"Negative: {negative_percentage:.2f}%\")\n",
    "        print(f\"Neutral: {neutral_percentage:.2f}%\")\n",
    "    else:\n",
    "        print(\"No tweets found for the user.\")\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    username = input(\"Enter the Twitter username: \")\n",
    "    analyze_user_sentiment(username)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid character '’' (U+2019) (2792038127.py, line 117)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[1], line 117\u001b[0;36m\u001b[0m\n\u001b[0;31m    * Based on the analysis and visualizations, it’s clear that similar genres tend to have data points that are located close to each other while similar types of songs are also clustered together.\u001b[0m\n\u001b[0m                                                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid character '’' (U+2019)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import plotly.express as px \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import euclidean_distances\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# **Read Data**\n",
    "data = pd.read_csv(\"../input/spotify-dataset/data/data.csv\")\n",
    "genre_data = pd.read_csv('../input/spotify-dataset/data/data_by_genres.csv')\n",
    "year_data = pd.read_csv('../input/spotify-dataset/data/data_by_year.csv')\n",
    "print(data.info())\n",
    "print(genre_data.info())\n",
    "print(year_data.info())\n",
    "We are going to check for all the analysis with the target as **'popularity'**. Before going to do that let's check for the Feature Correlation by considering a few features and for that, I'm going to use the **yellowbrick** package. You can learn more about it from the [documentation](https://www.scikit-yb.org/en/latest/index.html).\n",
    "from yellowbrick.target import FeatureCorrelation\n",
    "\n",
    "feature_names = ['acousticness', 'danceability', 'energy', 'instrumentalness',\n",
    "       'liveness', 'loudness', 'speechiness', 'tempo', 'valence','duration_ms','explicit','key','mode','year']\n",
    "\n",
    "X, y = data[feature_names], data['popularity']\n",
    "\n",
    "# Create a list of the feature names\n",
    "features = np.array(feature_names)\n",
    "\n",
    "# Instantiate the visualizer\n",
    "visualizer = FeatureCorrelation(labels=features)\n",
    "\n",
    "plt.rcParams['figure.figsize']=(20,20)\n",
    "visualizer.fit(X, y)     # Fit the data to the visualizer\n",
    "visualizer.show()\n",
    "# **Data Understanding by Visualization and EDA**\n",
    "# **Music Over Time**\n",
    "\n",
    "Using the data grouped by year, we can understand how the overall sound of music has changed from 1921 to 2020.\n",
    "def get_decade(year):\n",
    "    period_start = int(year/10) * 10\n",
    "    decade = '{}s'.format(period_start)\n",
    "    return decade\n",
    "\n",
    "data['decade'] = data['year'].apply(get_decade)\n",
    "\n",
    "sns.set(rc={'figure.figsize':(11 ,6)})\n",
    "sns.countplot(data['decade'])\n",
    "sound_features = ['acousticness', 'danceability', 'energy', 'instrumentalness', 'liveness', 'valence']\n",
    "fig = px.line(year_data, x='year', y=sound_features)\n",
    "fig.show()\n",
    "# **Characteristics of Different Genres**\n",
    "\n",
    "This dataset contains the audio features for different songs along with the audio features for different genres. We can use this information to compare different genres and understand their unique differences in sound.\n",
    "top10_genres = genre_data.nlargest(10, 'popularity')\n",
    "\n",
    "fig = px.bar(top10_genres, x='genres', y=['valence', 'energy', 'danceability', 'acousticness'], barmode='group')\n",
    "fig.show()\n",
    "# **Clustering Genres with K-Means**\n",
    "\n",
    "Here, the simple K-means clustering algorithm is used to divide the genres in this dataset into ten clusters based on the numerical audio features of each genres.\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "cluster_pipeline = Pipeline([('scaler', StandardScaler()), ('kmeans', KMeans(n_clusters=10, n_jobs=-1))])\n",
    "X = genre_data.select_dtypes(np.number)\n",
    "cluster_pipeline.fit(X)\n",
    "genre_data['cluster'] = cluster_pipeline.predict(X)\n",
    "# Visualizing the Clusters with t-SNE\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "tsne_pipeline = Pipeline([('scaler', StandardScaler()), ('tsne', TSNE(n_components=2, verbose=1))])\n",
    "genre_embedding = tsne_pipeline.fit_transform(X)\n",
    "projection = pd.DataFrame(columns=['x', 'y'], data=genre_embedding)\n",
    "projection['genres'] = genre_data['genres']\n",
    "projection['cluster'] = genre_data['cluster']\n",
    "\n",
    "fig = px.scatter(\n",
    "    projection, x='x', y='y', color='cluster', hover_data=['x', 'y', 'genres'])\n",
    "fig.show()\n",
    "# **Clustering Songs with K-Means**\n",
    "song_cluster_pipeline = Pipeline([('scaler', StandardScaler()), \n",
    "                                  ('kmeans', KMeans(n_clusters=20, \n",
    "                                   verbose=False, n_jobs=4))\n",
    "                                 ], verbose=False)\n",
    "\n",
    "X = data.select_dtypes(np.number)\n",
    "number_cols = list(X.columns)\n",
    "song_cluster_pipeline.fit(X)\n",
    "song_cluster_labels = song_cluster_pipeline.predict(X)\n",
    "data['cluster_label'] = song_cluster_labels\n",
    "# Visualizing the Clusters with PCA\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca_pipeline = Pipeline([('scaler', StandardScaler()), ('PCA', PCA(n_components=2))])\n",
    "song_embedding = pca_pipeline.fit_transform(X)\n",
    "projection = pd.DataFrame(columns=['x', 'y'], data=song_embedding)\n",
    "projection['title'] = data['name']\n",
    "projection['cluster'] = data['cluster_label']\n",
    "\n",
    "fig = px.scatter(\n",
    "    projection, x='x', y='y', color='cluster', hover_data=['x', 'y', 'title'])\n",
    "fig.show()\n",
    "# **Build Recommender System**\n",
    "\n",
    "* Based on the analysis and visualizations, it’s clear that similar genres tend to have data points that are located close to each other while similar types of songs are also clustered together.\n",
    "* This observation makes perfect sense. Similar genres will sound similar and will come from similar time periods while the same can be said for songs within those genres. We can use this idea to build a recommendation system by taking the data points of the songs a user has listened to and recommending songs corresponding to nearby data points.\n",
    "* [Spotipy](https://spotipy.readthedocs.io/en/2.16.1/) is a Python client for the Spotify Web API that makes it easy for developers to fetch data and query Spotify’s catalog for songs. You have to install using `pip install spotipy`\n",
    "* After installing Spotipy, you will need to create an app on the [Spotify Developer’s page](https://developer.spotify.com/) and save your Client ID and secret key.\n",
    "!pip install spotipy\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "from collections import defaultdict\n",
    "\n",
    "sp = spotipy.Spotify(auth_manager=SpotifyClientCredentials(client_id=os.environ[\"SPOTIFY_CLIENT_ID\"],\n",
    "                                                           client_secret=os.environ[\"SPOTIFY_CLIENT_SECRET\"]))\n",
    "\n",
    "def find_song(name, year):\n",
    "    song_data = defaultdict()\n",
    "    results = sp.search(q= 'track: {} year: {}'.format(name,year), limit=1)\n",
    "    if results['tracks']['items'] == []:\n",
    "        return None\n",
    "\n",
    "    results = results['tracks']['items'][0]\n",
    "    track_id = results['id']\n",
    "    audio_features = sp.audio_features(track_id)[0]\n",
    "\n",
    "    song_data['name'] = [name]\n",
    "    song_data['year'] = [year]\n",
    "    song_data['explicit'] = [int(results['explicit'])]\n",
    "    song_data['duration_ms'] = [results['duration_ms']]\n",
    "    song_data['popularity'] = [results['popularity']]\n",
    "\n",
    "    for key, value in audio_features.items():\n",
    "        song_data[key] = value\n",
    "\n",
    "    return pd.DataFrame(song_data)\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import euclidean_distances\n",
    "from scipy.spatial.distance import cdist\n",
    "import difflib\n",
    "\n",
    "number_cols = ['valence', 'year', 'acousticness', 'danceability', 'duration_ms', 'energy', 'explicit',\n",
    " 'instrumentalness', 'key', 'liveness', 'loudness', 'mode', 'popularity', 'speechiness', 'tempo']\n",
    "\n",
    "\n",
    "def get_song_data(song, spotify_data):\n",
    "    \n",
    "    try:\n",
    "        song_data = spotify_data[(spotify_data['name'] == song['name']) \n",
    "                                & (spotify_data['year'] == song['year'])].iloc[0]\n",
    "        return song_data\n",
    "    \n",
    "    except IndexError:\n",
    "        return find_song(song['name'], song['year'])\n",
    "        \n",
    "\n",
    "def get_mean_vector(song_list, spotify_data):\n",
    "    \n",
    "    song_vectors = []\n",
    "    \n",
    "    for song in song_list:\n",
    "        song_data = get_song_data(song, spotify_data)\n",
    "        if song_data is None:\n",
    "            print('Warning: {} does not exist in Spotify or in database'.format(song['name']))\n",
    "            continue\n",
    "        song_vector = song_data[number_cols].values\n",
    "        song_vectors.append(song_vector)  \n",
    "    \n",
    "    song_matrix = np.array(list(song_vectors))\n",
    "    return np.mean(song_matrix, axis=0)\n",
    "\n",
    "\n",
    "def flatten_dict_list(dict_list):\n",
    "    \n",
    "    flattened_dict = defaultdict()\n",
    "    for key in dict_list[0].keys():\n",
    "        flattened_dict[key] = []\n",
    "    \n",
    "    for dictionary in dict_list:\n",
    "        for key, value in dictionary.items():\n",
    "            flattened_dict[key].append(value)\n",
    "            \n",
    "    return flattened_dict\n",
    "\n",
    "\n",
    "def recommend_songs( song_list, spotify_data, n_songs=10):\n",
    "    \n",
    "    metadata_cols = ['name', 'year', 'artists']\n",
    "    song_dict = flatten_dict_list(song_list)\n",
    "    \n",
    "    song_center = get_mean_vector(song_list, spotify_data)\n",
    "    scaler = song_cluster_pipeline.steps[0][1]\n",
    "    scaled_data = scaler.transform(spotify_data[number_cols])\n",
    "    scaled_song_center = scaler.transform(song_center.reshape(1, -1))\n",
    "    distances = cdist(scaled_song_center, scaled_data, 'cosine')\n",
    "    index = list(np.argsort(distances)[:, :n_songs][0])\n",
    "    \n",
    "    rec_songs = spotify_data.iloc[index]\n",
    "    rec_songs = rec_songs[~rec_songs['name'].isin(song_dict['name'])]\n",
    "    return rec_songs[metadata_cols].to_dict(orient='records')\n",
    "recommend_songs([{'name': 'Come As You Are', 'year':1991},\n",
    "                {'name': 'Smells Like Teen Spirit', 'year': 1991},\n",
    "                {'name': 'Lithium', 'year': 1992},\n",
    "                {'name': 'All Apologies', 'year': 1993},\n",
    "                {'name': 'Stay Away', 'year': 1993}],  data)\n",
    "* This last cell will gives you a recommendation list of songs like this,\n",
    "\n",
    "\n",
    "```\n",
    "[{'name': 'Life is a Highway - From \"Cars\"',\n",
    "  'year': 2009,\n",
    "  'artists': \"['Rascal Flatts']\"},\n",
    " {'name': 'Of Wolf And Man', 'year': 1991, 'artists': \"['Metallica']\"},\n",
    " {'name': 'Somebody Like You', 'year': 2002, 'artists': \"['Keith Urban']\"},\n",
    " {'name': 'Kayleigh', 'year': 1992, 'artists': \"['Marillion']\"},\n",
    " {'name': 'Little Secrets', 'year': 2009, 'artists': \"['Passion Pit']\"},\n",
    " {'name': 'No Excuses', 'year': 1994, 'artists': \"['Alice In Chains']\"},\n",
    " {'name': 'Corazón Mágico', 'year': 1995, 'artists': \"['Los Fugitivos']\"},\n",
    " {'name': 'If Today Was Your Last Day',\n",
    "  'year': 2008,\n",
    "  'artists': \"['Nickelback']\"},\n",
    " {'name': \"Let's Get Rocked\", 'year': 1992, 'artists': \"['Def Leppard']\"},\n",
    " {'name': \"Breakfast At Tiffany's\",\n",
    "  'year': 1995,\n",
    "  'artists': \"['Deep Blue Something']\"}]\n",
    "```\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
